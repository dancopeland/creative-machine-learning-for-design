{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dancopeland/creative-machine-learning-for-design/blob/master/4453x_homework1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1 | Classification üêïüê±\n",
        "4.453x Creative Machine Learning for Design<br/>\n",
        "*Renaud Danhaive, Ous Abou Ras, Natasha Hirt, Caitlin Mueller*\n",
        "<br/><br/>\n",
        "\n",
        "---\n",
        "\n",
        "üëãüëã Welcome to the first homework of 4.453x!! üòÉüéà\n",
        "<br/><br/>\n",
        "In this assignment, you will train a model to recognize cats from dogs based on a limited dataset that we have pre-processed from the Kaggle Cats and Dogs dataset separately using Tensorflow's API (Tensorflow is another deep learning framework) which provides easy abstractions to download all kinds of datasets.\n",
        "\n",
        "We worked through a very similar notebook in Lecture 1.  Like we saw in this first notebook on transfer learning with a tiny self-generated dataset, it's hard to make things work really well if your dataset is really too small. Here, we have a slightly more substantial dataset (still tiny in modern terms) that should help us achieve decent performance.\n",
        "\n",
        "This notebook jumps ahead a bit in terms of machine learning concepts and implementation.  We will return to these concepts in a deeper, more systematic manner as we progress in the semester.  The purpose of this assignment and notebook is to help you build confidence programming in Colab notebook environments and get comfortable working with data and external libraries.\n",
        "\n",
        "The code below provides a skeleton around the questions you are asked to complete. Questions and instructions are directly in the body of the notebook.\n",
        "<br/><br/>\n",
        "\n",
        "‚ùó‚ùó‚ùó\n",
        "\n",
        "The deliverable for this homework is a *viewable* link to your completed and runnable notebook that implements the requested code. For questions that require you to submit a textual or visual answer, please collect your results in a separate Google Docs file to be shared at the end of the notebook. For questions that request numerical results, you may simply print them with your code.\n",
        "\n",
        "‚ùó‚ùó‚ùó\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3V76Tl6xNv_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Let's introduce some coding best practices. Why? Well, we need to read your code, but more importantly *you* may need to re-read your code at some point. Simple coding practices help you structure your mind and code faster.\n",
        "We recommend the following practices:\n",
        "- Explicit is better than implicit when naming objects. For example, a variable pointing to an array of dog images is better named as `dog_images_array` than as `d_array`.\n",
        "- Don't repeat yourself (DRY). If you find yourself copy-pasting code, it's a good sign you should put that code in a function.\n",
        "- Try to produce code that could almost be read as a sentence by somebody with some knowledge of what the code is trying to accomplish.\n",
        "- More readable code is (almost always) better code.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vJQucrzQUpJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.0 | Imports üì¶"
      ],
      "metadata": {
        "id": "lL4DShDzRTbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "QQk7ew9aRSgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1.0 | Download and inspect the dataset\n",
        "\n",
        "\n",
        "### 1.1 | Download the dataset\n",
        "\n",
        "We'll download the dataset to the local storage of this runtime. To do so easily, we'll use command line tool called `gdown` specifically designed to download files from Google Drive. In Colab, if you start a line of code with `!`, that line is run in the command line. This allows to install missing packages or download things easily from the web to the local storage. To install `gdown`, we just need to run `!pip install gdown`.\n",
        "\n",
        "Note: you may have to run this cell twice to actually download the file to `dogs_cats.npz` as Colab sometimes returns a warning first."
      ],
      "metadata": {
        "id": "hv1HkYrKRnhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown > /dev/null\n",
        "!gdown https://drive.google.com/uc?id=1SnEDJg3DFsFvSU3VX1L3Dj3LrR2uBGuC"
      ],
      "metadata": {
        "id": "ncjXo6kTXa2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b050f562-aadc-47fc-eb39-c8b728820801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SnEDJg3DFsFvSU3VX1L3Dj3LrR2uBGuC\n",
            "To: /content/processedDogCat.npz\n",
            "100% 540M/540M [00:03<00:00, 144MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 | Load the dataset\n",
        "Ok, so we've got our dataset in the file `processedDogCat.npz`. `.npz` is a special format that can be read by `numpy`, so let's load the data contained in the file in a variable."
      ],
      "metadata": {
        "id": "K8rMiAk2YrHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = np.load(\"processedDogCat.npz\", allow_pickle=True)"
      ],
      "metadata": {
        "id": "kJTdZvZRYq0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 | Inspect this dataset"
      ],
      "metadata": {
        "id": "f54OlP9WbNwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(dataset.keys()))"
      ],
      "metadata": {
        "id": "UsXK9P7cXmKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680f4de3-9f9e-4e20-898c-80be51eee27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['X', 'Y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see the dataset has two entries `X` (the input features or images) and `Y` the target classes."
      ],
      "metadata": {
        "id": "T-HVAioCbbJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset[\"X\"]\n",
        "Y = dataset[\"Y\"]"
      ],
      "metadata": {
        "id": "06kwzlprbMel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 ‚ùì Print the shapes of the X and Y arrays. \n",
        "‚ùó How many samples are there in the dataset?  In other words, what are the dimensions of the X and Y arrays?  *Hint: the `np.shape` function may be useful here.*\n"
      ],
      "metadata": {
        "id": "QkXZuxgcbvGb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FFIEUqaqbuod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 ‚ùì Plot 5 random images from X (input)"
      ],
      "metadata": {
        "id": "twvcpLuyb_C7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrr9lXnHbqf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.6 ‚ùì What are the target labels in Y and which one corresponds to the \"Dog\" category?"
      ],
      "metadata": {
        "id": "SRwFnX1QcJRa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0bErY7ccI44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Each datapoint in the dataset ia a 150-by-150 RGB image and its associated class. First, we'll shuffle the dataset because it is currently ordered by class (not something you usually want for training). Shuffling the dataset will also allow you to easily set aside a part of your dataset for validation/testing."
      ],
      "metadata": {
        "id": "KLDfzI11cfv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.7 ‚ùì Shuffle the dataset \n",
        "You can use `sklearn.utils.shuffle`.  Remember that we want to keep X and Y together so that the class labels stay with their associated images."
      ],
      "metadata": {
        "id": "EDhONY-8dzd_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vk9H4b3hce-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.8 ‚ùì What is the range of the pixel values?"
      ],
      "metadata": {
        "id": "onQSb4czceEd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KKYQpebxeHLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2.0 | Processing the images into extracted features using VGG16\n",
        "Take inspiration from the code in the [L01 notebook](https://colab.research.google.com/drive/1GTWORtS_bU__mH33_Mput_KYxYopqBuV?usp=sharing). Make sure to use the GPU!\n",
        "\n",
        "\n",
        "You will need to resize the arrays/tensors from their current size (which is too small) to the minimum size accepted by VGG16 (224 by 224). To do so, we recommend you use `torchvision.transforms.Resize` (note this transformation can be applied on a batch of multiple images at once).\n",
        "\n",
        "‚ùó‚ùó Because we are handling many more images than we did in the lecture notebook, you may need to process them in batches (hint: you need to do it if you encounter a RAM or CUDA memory issue)."
      ],
      "metadata": {
        "id": "8XrC5plmeNfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 ‚ùì Convert the array X to a tensor"
      ],
      "metadata": {
        "id": "oWWG0mnaf01n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Nz5yIRBeJPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 ‚ùì Resize the image tensors. \n",
        "Remember that we need to permute the array to format the tensors in the anticipated way."
      ],
      "metadata": {
        "id": "eoRgt60lf-Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WOcNd3Atf-gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 ‚ùì Normalize the image tensors using the normalization constants expected by VGG16."
      ],
      "metadata": {
        "id": "-cl_jwyIgFJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9kHSXb9ggI69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 ‚ùì Project the image tensors to their bottleneck features"
      ],
      "metadata": {
        "id": "PYenYK_qgQub"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4MEH9g2gQct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 ‚ùì Flatten the resulting *feature maps* (not the batches!)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "V1HGasafgXo1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYocnyq0gYon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6 ‚ùì Convert the result back to numpy"
      ],
      "metadata": {
        "id": "xfn6CPF7gr5F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cAvymU_CgrJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to test how our model fares on unseen data, we need to set aside data that is not used during training. This data is our *validation* data and computing the accuracy of our model on this data gives us an idea of the *generalization error* of our model.\n",
        "\n",
        "This is a really important process in ML, because in some sense predicting things perfectly on the training set does not matter (think of how stupidly replicating the data achieves perfect prediction). Generally, you would even want another test set, but we'll talk more about this in later weeks.\n",
        "\n",
        "### 2.7 ‚ùì Separate the dataset in a training set (90% of the data) and a validation set (10% of the data)"
      ],
      "metadata": {
        "id": "e7jprXgJg90m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SXI0rcKTg-S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3.0 | Fit k-NN model\n",
        "Like in the [L01 notebook](https://colab.research.google.com/drive/1GTWORtS_bU__mH33_Mput_KYxYopqBuV?usp=sharing), fit a k-nearest neighbors model with $k=10$ to your training set.\n",
        "\n",
        "Remember, the task of the model is to try to predict whether a given image shows a dog or a cat. This is a VERY important model that could change the world as we know it. üö®üö®üö®üö®\n",
        "\n",
        "### 3.1 ‚ùì Fit a k-nearest neighbors model to your training set"
      ],
      "metadata": {
        "id": "cy0ONGTwgppV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BfdcsjJgisWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 ‚ùì Compute the accuracy of the model on the training and validation sets (separately). Is the model doing well? \n",
        "‚ùó Record the values found and your observations in the Google Doc you link at the end of the notebook.\n",
        "\n",
        "Hint: we measure accuracy as `number_correct_predictions/total_number_predictions`. "
      ],
      "metadata": {
        "id": "YjEcGwxUiswr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsjGM7d6j6Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 ‚ùì Plot images of 5 good predictions and 5 bad predictions. Can you observe patterns in the bad prediction?\n",
        "‚ùó Record these images and your observations in the Google Doc you link at the end of the notebook."
      ],
      "metadata": {
        "id": "eLS7cjIUj6i4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cTOM08lfky64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 ‚ùì Test 5 different values of $k$ and compute the validation accuracy of each resulting model. What is the best of value of $k$ that you found?\n",
        "‚ùó Record your observations in the Google Doc you link at the end of the notebook.\n"
      ],
      "metadata": {
        "id": "GTl5ABCpkzlj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fm9ccRCAkz3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submit a link to the document where you recorded the requested observations below. Make sure it is viewable by the teaching staff. \n",
        "\n",
        "Your link üíª >"
      ],
      "metadata": {
        "id": "SeghIowXli7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Congratulations, you're done! üí™ There was a lot of brand new stuff here, you should be proud of yourself!! üëè‚ö°"
      ],
      "metadata": {
        "id": "O2vzrWF9ltr0"
      }
    }
  ]
}